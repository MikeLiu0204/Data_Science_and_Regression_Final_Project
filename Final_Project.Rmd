---
title: "Exploration of the Influential Factor of the Election Results in 2008"
author: "Daisy, Mike, and Osvaldo"
output: pdf_document
date: "2024-12-05"
---

```{r setup, include=FALSE}
# consider removing code from knit file
knitr::opts_chunk$set(echo = TRUE)

```

```{r}
library(Stat2Data)
data("Election08")
```
## Abstract
This project examines state-level factors predicting whether Barack Obama or John McCain won the 2008 U.S. presidential election. Logistic regression models analyze and compare predictors, identifying the most significant contributors to election outcomes.

## Introduction
The goal is to use logistic regression to determine which state-level socioeconomic and political factors best predict election results. This analysis helps understand the relationships among predictors like income, education levels, and political leanings.

# Research Question
What is the most influential factor in predicting the presidential election result in 2008?

# Expected Findings
Note the target population.


# Methodology
The dataset of reference contains information from all 50 states and the District of Columbia for the 2008 U.S. presidential election. This analysis consists of 5 models, 4 of which investigate if Income (the Per capita income in the state as of 2007 (in dollars)), HS (percentage of adults with at least a high school education), BA (percentage of adults with at least a high school education), and Dem.Rep (the difference in the percentage of Democrats and the percentage of Republicans) is associated with the odds that Obama (Democrat) wins state in 2008 (ObamaWin = 1), and 1 of which is an interaction model that investigates the joint effect of these four variables.

# Dataset Information
data(Election08)
str(Election08)
summary(Election08)
The dataset includes 51 observations (50 states + DC) with variables related to income, education, and political alignment. The dependent variable is `ObamaWin`, a binary outcome (1 = Obama won, 0 = McCain won).

# Process
summary(Election08)

# Visualize relationships
ggplot(Election08, aes(x = Income, y = Dem.Rep, color = factor(ObamaWin))) +
  geom_point() + labs(color = "Obama Win")

# Check Conditions
The conditions for logistic regressions are linearity, randomness, and independence. 
Linearity: this means that there should exist a linear relationship between log(odds) and the predictor.
The process of data collection is assumed to be random, and each observation is assumed to be independent.

logistic_model <- glm(ObamaWin ~ Income + HS + BA + Dem.Rep, data = Election08, family = "binomial")

Election08$logit <- predict(logistic_model, type = "link")  # Logit values

ggplot(Election08, aes(x = Income, y = logit)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = "Linearity Check: Income vs Logit", x = "Income", y = "Logit")

ggplot(Election08, aes(x = HS, y = logit)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = "Linearity Check: HS vs Logit", x = "HS", y = "Logit")

ggplot(Election08, aes(x = BA, y = logit)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = "Linearity Check: BA vs Logit", x = "BA", y = "Logit")

ggplot(Election08, aes(x = Dem.Rep, y = logit)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = "Linearity Check: Dem.Rep vs Logit", x = "Dem.Rep", y = "Logit")

# Correlation matrix
cor_matrix <- cor(Election08[, c("Income", "HS", "BA", "Dem.Rep")])
print(cor_matrix)

# Variance Inflation Factor (VIF)
vif(lm(Dem.Rep ~ Income + HS + BA, data = Election08))

# Logistic regression for each predictor
models <- list(
  Income = glm(ObamaWin ~ Income, data = Election08, family = "binomial"),
  HS = glm(ObamaWin ~ HS, data = Election08, family = "binomial"),
  BA = glm(ObamaWin ~ BA, data = Election08, family = "binomial"),
  DemRep = glm(ObamaWin ~ Dem.Rep, data = Election08, family = "binomial")
)

# Summarize models
lapply(models, summary)

final_model <- glm(ObamaWin ~ Income + HS + BA + Dem.Rep, data = Election08, family = "binomial")
summary(final_model)

# Model Comparison
compare_metrics <- function(model, data, response) {
  # Predicted probabilities
  preds <- predict(model, type = "response")
  # Binary classification (threshold = 0.5)
  preds_class <- ifelse(preds > 0.5, 1, 0)
  
  # SSE: Sum of Squares for Error
  sse <- sum((data[[response]] - preds_class)^2)
  
  # SSM: Sum of Squares for Model
  mean_response <- mean(data[[response]])
  ssm <- sum((preds_class - mean_response)^2)
  
  # SSR: Total Sum of Squares
  ssr <- sum((data[[response]] - mean_response)^2)
  
  # R-squared
  r_squared <- 1 - (sse / ssr)
  
  # Adjusted R-squared
  n <- nrow(data)
  p <- length(coef(model)) - 1
  adj_r_squared <- 1 - ((1 - r_squared) * (n - 1) / (n - p - 1))
  
  list(SSE = sse, SSM = ssm, SSR = ssr, R_squared = r_squared, Adjusted_R_squared = adj_r_squared)
}

# Compute metrics for all models
model_metrics <- lapply(models, function(m) compare_metrics(m, Election08, "ObamaWin"))
model_metrics[["Final Model"]] <- compare_metrics(final_model, Election08, "ObamaWin")
model_metrics

# Conclusion
